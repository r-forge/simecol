\documentclass[report,nojss]{vignette}

\DeclareGraphicsExtensions{.pdf,.eps}
%% need no \usepackage{Sweave}

\usepackage{amsmath,amssymb,thumbpdf}
\usepackage{textcomp}%has degree celsius

\renewcommand{\textfraction}{0.2}
\renewcommand{\bottomfraction}{0.7}
\renewcommand{\topfraction}{0.7}
\renewcommand{\floatpagefraction}{0.8}

%Numbering of sections
\setcounter{secnumdepth}{3}
%Numbering within TOC
\setcounter{tocdepth}{3}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Thomas Petzoldt\\ Technische Universit\"at Dresden}

\title{\pkg{simecol}-Howto: Tips, Tricks and Building Blocks}
%\VignetteIndexEntry{Introduction to the simecol package}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Thomas Petzoldt} %% comma-separated
\Plaintitle{simecol-Howto: Tips, Tricks and Building Blocks} %% without formatting
\Shorttitle{simecol-Howto} %% a short title (if necessary)
%\VignetteIndexEntry{simecol-Howto: Tips, Tricks and Building Blocks}

%% an abstract and keywords
\Abstract{
  \flushleft %% workaround for the report style

  This document is a loose collection of chapters that describe
  different aspects of modelling and model implementation in
  \proglang{R} with the \pkg{simecol} package.  It supplements the
  original publication of \citet{Petzoldt2007} from which an updated
  version, \textbf{simecol-introduction}, is also part of this
  package. Please refer to the JSS publication when citing this work.
}

\Keywords{\proglang{R}, \pkg{simecol}, ecological modeling,
  object-oriented programming (OOP), compiled code, debugging}

\Plainkeywords{R, simecol, ecological modeling, compiled code,
  debugging} %% without formatting

\Address{
  Thomas Petzoldt\\
  Institut f\"ur Hydrobiologie\\
  Technische Universit\"at Dresden\\
  01062 Dresden, Germany\\
  E-mail: \email{thomas.petzoldt@tu-dresden.de}\\
  URL: \url{http://tu-dresden.de/Members/thomas.petzoldt/}\\
}

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}
%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

\SweaveOpts{engine=R, eps=FALSE, fig=FALSE, echo=TRUE, include=FALSE, prefix.string=howto, width=6, height=4}

<<init,echo=FALSE, include=FALSE, fig=FALSE>>=
library("simecol")
data(lv, package = "simecol")
options("width"=72)
options("prompt" = "R> ", "continue" = "+  ")
@


\tableofcontents

%% ======================================================================
\chapter{The Basics}

\section[Building simecol objects]{Building \pkg{simecol} objects}

The intention behind \pkg{simecol} is the construction of
``all-in-one'' model objects. That is, everything that defines one
particular model, equations and data are stored together in one
\code{simObj} (spoken: sim-Object), and only some general algorithms
(e.g. differential equation solvers or interpolation routines) remain
external, preferably as package functions (e.g. function \code{lsoda}
in the package \pkg{deSolve} \citep{deSolve2009} or as functions in the
user workspace.

This strategy has three main advantages:

\begin{enumerate}
\item You can have several independent versions of one model in the
  computer memory at the same time. These instances may have different
  settings, parameters and data or even use different formula, but
  they do not interfere with each other.  Moreover, if all data and
  functions are \emph{encapsulated} in their \code{simObj}ects,
  identifiers can be re-used and it is, for example, not necessary to
  keep track over a large number of variable names or to invent new
  identifiers for parameter sets of different scenarios.
\item You can give \code{simObj}ects away, either in binary form or as
  source code objects. Everything essential to run such a model is
  included, not only the formula but also defaults for parameter and
  data. You, or your users need only \proglang{R}, some packages and
  your model object. It is also possible to start model objects
  directly from the internet or, on the other hand, to distribute
  model collections as \proglang{R} packages.
\item All \code{simObj}ects can be handled, simulated and modified
  with the same generic functions, e.g. \code{sim}, \code{plot} or
  \code{parms}.  Your users can start playing with your models without
  the need to understand all the internals.
\end{enumerate}

While it is, of course, preferable to have all parts of a model
encapsulated in one object, it is not mandatory to have the complete
working model object before starting to use \pkg{simecol}.

\pkg{simecol} models (in the following called \code{simObj}ects) can
be built step by step, starting with mixed applications composed by
rudimentary \code{simObj}ects and ordinary user space functions. When
everything works, you should encapsulate all the main parts of your
model in the \code{simObj}ect to get a clean object that does not
interfere with others.

\subsection{An Example}

We start with the example given in the simecol-introduction
\citep{Petzoldt2007}, an implementation of the UPCA model of
\citet{Blasius1999}, but we write it in the usual \pkg{deSolve} style,
i.e. without using \pkg{simecol}:

<<upca1>>=
f <- function(x, y, k){x*y / (1+k*x)}  # Holling II

func <- function(time, y, parms) {
  with(as.list(c(parms, y)), {
    du <-  a * u           - alpha1 * f(u, v, k1)
    dv <- -b * v           + alpha1 * f(u, v, k1) +
                           - alpha2 * f(v, w, k2)
    dw <- -c * (w - wstar) + alpha2 * f(v, w, k2)
    list(c(du, dv, dw))
  })
}

times  <- seq(0, 100, 0.1)
parms  <- c(a=1, b=1, c=10, alpha1=0.2, alpha2=1, k1=0.05, k2=0, wstar=0.006)
y      <- c(u=10, v=5, w=0.1)
@

The model is defined by 5 variables in the \proglang{R} user workspace,
namely \code{f}, \code{func}, \code{times}, \code{parms} and
\code{init}.  The implementation is similar to the help page examples
of package \pkg{deSolve} and we can solve it exactly in the same
manner:

<<upca2, fig=TRUE>>=
library(deSolve)
out <- lsoda(y, times, func, parms)
matplot(out[,1], out[,-1], type="l")
@

\begin{figure}
\centering
\includegraphics[width=\textwidth]{howto-upca2}
\caption{\label{howto-upca1} Output of UPCA model, solved with \code{lsoda}
from package \pkg{deSolve}.}
\end{figure}


\subsection{Transition to simecol} \label{s4definition}

If we compare this example with the \pkg{simecol} structure, we may
see that they are kind of similar. This obvious coincidence is quite
natural, because the notation of both, \pkg{deSolve} and
\pkg{simecol}, is based on the state-space notation of control
theory\footnote{see
  \url{http://en.wikipedia.org/wiki/State_space_(controls)}, version
  of 2008-11-01}.

Due to this, only small restructuring and renaming is needed to form a
\code{simObj}:

<<upca3, keep.source=TRUE>>=
library("simecol")
f <- function(x, y, k){x*y / (1+k*x)}  # Holling II

upca <- new("odeModel",
  main = function(time, y, parms) {
    with(as.list(c(parms, y)), {
      du <-  a * u           - alpha1 * f(u, v, k1)
      dv <- -b * v           + alpha1 * f(u, v, k1) +
                             - alpha2 * f(v, w, k2)
      dw <- -c * (w - wstar) + alpha2 * f(v, w, k2)
      list(c(du, dv, dw))
    })
  },
  times  = seq(0, 100, 0.1),
  parms  = c(a=1, b=1, c=10, alpha1=0.2, alpha2=1,
    k1=0.05, k2=0, wstar=0.006),
  init   = c(u=10, v=5, w=0.1),
  solver = "lsoda"
)
@

You may notice that the assignment operators ``\code{<-}'' changed to
a declarative equal sign ``\code{=}'' for the slot definitions, that
some of the names (\code{y}, \code{func}) were changed to the
pre-defined slot names of \pkg{simecol} and that all the slot
definitions are now comma separated arguments of the \code{new}
function that creates the \code{upca} object. The solver method
\code{lsoda} is also given as a character string pointing to the
original \code{lsoda} function in package \pkg{deSolve}.

The new object can now be simulated very easily with the \code{sim}
function of \pkg{simecol} that returns the object with all original
slots and one additional slot \code{out} holding the output values.  A
generic \code{plot} function is also available for basic plotting of
the output:

<<upca4>>=
upca <- sim(upca)
plot(upca)
@

It is now also possible to extract the results from \code{upca} with a
so called accessor function \code{out}, and to use arbitrary,
user-defined plot functions:

<<upca5, fig=TRUE>>=
plotupca <- function(obj, ...) {
  o <- out(obj)
  matplot(o[,1], o[,-1], type="l", ...)
  legend("topright", legend = c("u", "v", "w"), lty=1:3, , bg="white",col = 1:3)
}
plotupca(upca)
@

%\begin{figure}
%\centering
%\includegraphics[width=\textwidth]{howto-upca5}
%\caption{\label{howto-upca5} A user-defined plot function.}
%\end{figure}


Okay, that's it, but note that function \code{f} is not yet part of
the simecol object, that's why we call here a ``mixed
implementation''. This function \code{f} is rather simple here, but it
would be also possible to call functions of arbitrary complexity from
\code{main}.

\subsection{Creating scenarios}

After defining one \code{simecol} object (that we can call a parent
object or a \textbf{prototype}), we may create derived objects, simply
by copying (cloning) and modification.  As an example, we create two
scenarios with different parameter sets:

<<upca6, fig=TRUE>>=
sc1 <- sc2 <- upca
parms(sc1)["wstar"] <- 0
parms(sc2)["wstar"] <- 0.1
sc1 <- sim(sc1)
sc2 <- sim(sc2)
par(mfrow=c(1,2))
plotupca(sc1, ylim=c(0, 250))
plotupca(sc2, ylim=c(0, 250))
@

\begin{figure}
\centering
\includegraphics[width=\textwidth]{howto-upca6}
\caption{\label{howto-upca6} Two scenarios of the UPCA model (left:
  wstar=0, right: wstar=0.1; functional response f is Holling II).}
\end{figure}

If we simulate and plot these scenarios, we see an exponentially
growing $u$ in both cases, and cycles resp. an equilibrium state for
$v$ and $w$ for the scenarios respectively (figure \ref{howto-upca6}).

If we now also change the functional response function $f$ from Holling II
to Lotka-Volterra:

<<upca7>>=
f <- function(x, y, k){x * y}
@

both model scenarios, \code{sc1} and \code{sc2} are affected by this
new definition.

<<upca8,fig=TRUE>>=
sc1 <- sim(sc1)
sc2 <- sim(sc2)
par(mfrow=c(1,2))
plotupca(sc1, ylim=c(0, 20))
plotupca(sc2, ylim=c(0, 20))
@

\begin{figure}
\centering
\includegraphics[width=\textwidth]{howto-upca8}
\caption{\label{howto-upca8} Two scenarios of the UPCA model (left:
  wstar=0, right: wstar=0.1; functional response f is Holling II).}
\end{figure}

Now, we get a stable cycle for $u$ and $v$ in scenario 1 and an
equilibrium for all state variables in scenario 2 (figure
\ref{howto-upca8}). You may also note that the new function \code{f}
has exactly the same parameters as above, including the, in the second
case obsolete, parameter \code{k}.

In the examples above, function \code{f} was an ordinary function in
the user workspace, but it is also possible to implement such
functions (or sub-models) directly as part of the model object. As one
possibility, one might consider to define local functions within
\code{main}, but that would have the disadvantage that such functions
are not easily accessible from outside.

To allow the latter, \pkg{simecol} has an optional slot ``equations'',
that can hold a list of submodels. Such an equations-slot can be
defined either during object creation, or functions may be added
afterwards. In the following, we derive two new clones with default
parameter settings from the original \code{upca}-object, and then
assign one version (the Holling II functional response) to scenario 1
and the other version (simple multiplicative Lotka-Volterra functional
response) to scenario 2 (figure \ref{howto-upca9}):

<<upca9,fig=TRUE>>=
sc1 <- sc2 <- upca
equations(sc1)$f <- function(x, y, k){x*y / (1+k*x)}
equations(sc2)$f <- function(x, y, k){x * y}
sc1 <- sim(sc1)
sc2 <- sim(sc2)
par(mfrow=c(1,2))
plotupca(sc1, ylim=c(0, 20))
plotupca(sc2, ylim=c(0, 20))
@

\begin{figure}
\centering
\includegraphics[width=\textwidth]{howto-upca9}
\caption{\label{howto-upca9} Two scenarios of the UPCA model (left:
  functional response \code{f} is Holling II, right functional
  response is Lotka-Volterra).}
\end{figure}

This method allows to compare models with different structures in the
same way as scenarios with different parameter values. In addition,
it is also possible to define model objects with different versions of
\textbf{built-in} submodels, that can be alternatively enabled:

<<upca10>>=
upca <- new("odeModel",
  main = function(time, y, parms) {
    with(as.list(c(parms, y)), {
      du <-  a * u           - alpha1 * f(u, v, k1)
      dv <- -b * v           + alpha1 * f(u, v, k1) +
                             - alpha2 * f(v, w, k2)
      dw <- -c * (w - wstar) + alpha2 * f(v, w, k2)
      list(c(du, dv, dw))
    })
  },
  equations  = list(
    f1 = function(x, y, k){x*y},           # Lotka-Volterra
    f2 = function(x, y, k){x*y / (1+k*x)}  # Holling II
  ),
  times  = seq(0, 100, 0.1),
  parms  = c(a=1, b=1, c=10, alpha1=0.2, alpha2=1, k1=0.05, k2=0, wstar=0.006),
  init   = c(u=10, v=5, w=0.1),
  solver = "lsoda"
)

equations(upca)$f <- equations(upca)$f1
@

\subsection{Debugging}

As stated before, all-in-one encapsulation of all functions and data
in \code{simObj}ects has many advantages, but there is also one
disadvantage, namely debugging.  Debugging of \proglang{S4} objects is
sometimes cumbersome, especially if slot-functions (e.g. \code{main},
\code{equations}, \code{initfunc}) come into play. These difficulties
are not much important for well-functioning ready-made model objects,
but they appear as an additional burden during model building, in
particular if these models are technically not as simple as in our
example.

%\subsubsection{Method 1: Debug functions in the user workspace}

Fortunately, there are easy workarounds. One of them is implementing
the technically challenging parts in the user-workspace first using
the above mentioned mixed style. Then, after developing and debugging
the model and if everything works satisfactory, integrating the parts
into the object is straightforward, given that you keep the general
structure in mind. In the example below, we implement the main model
as a workspace function \code{fmain}\footnote{Note that this function
  must never be named ``func'', for some rather esoteric internal
  reasons which we shall not discuss further here.}  with the same
interface (parameters and return values) as above, which is then
called by the \code{main}-function of the \code{simObj}:

<<upca11>>=
f <- function(x, y, k){x*y / (1+k*x)}  # Holling II

fmain <-  function(time, y, parms) {
  with(as.list(c(parms, y)), {
    du <-  a * u           - alpha1 * f(u, v, k1)
    dv <- -b * v           + alpha1 * f(u, v, k1) +
                           - alpha2 * f(v, w, k2)
    dw <- -c * (w - wstar) + alpha2 * f(v, w, k2)
    list(c(du, dv, dw))
  })
}

upca <- new("odeModel",
  main = function(time, y, parms) fmain(time, y, parms),
  times  = seq(0, 100, 0.1),
  parms  = c(a=1, b=1, c=10, alpha1=0.2, alpha2=1, k1=0.05, k2=0, wstar=0.006),
  init   = c(u=10, v=5, w=0.1),
  solver = "lsoda"
)
@

This function \code{fmain} as well as any other submodels like
\code{f} can now be debugged with the usual \proglang{R} tools,
e.g. \code{debug}:

<<eval=FALSE>>=
debug(fmain)
upca <- sim(upca)
@

Debugging can be stopped by \code{undebug(fmain)}. If everything
works, you can add the body of \code{fmain} to \code{upca} manually,
and it is even possible to do this in the formalized \code{simecol}
way of object modification:

<<upca12, keep.source=TRUE>>=
main(upca)        <- fmain   # assign workspace function to main slot
equations(upca)$f <- f       # assign workspace function to equations
rm(fmain, f)   # optional, for saving memory and avoiding confusion
str(upca)      # show the object
@

Now, you can delete \code{f} and \code{fmain} and you have a clean
workspace with only the necessary objects.

%\subsubsection{Method 2: Extract functions temporarily}


\section{Different ways to store simObjects}

One of the main advantages of \pkg{simecol} is, that model objects can
be made persistent and that it is easy to distribute and share
\code{simObj}ects over the internet.

The most obvious and simple form is, of course, to use the original
source code of the objects, i.e. the function call to \code{new} with
all the slots which creates the \proglang{S4}-object (see section
\ref{s4definition}), but there are also other possibilities.

\pkg{simecol} objects can be saved in machine readable form as
\proglang{S4}-object binaries with the \code{save} method of
\proglang{R}, which stores the whole object with all its equations,
initial values, parameters etc. and also the simulation output if the
model was simulated before saving.

<<upca13, keep.source=TRUE>>=
save(upca, file="upca.Rdata")  # persistent storage of the model object
load("upca.Rdata")             # load the model
@

Conversion of the \proglang{S4} object to a list representation is
another possibility, that yields a representation that is readable by
humans \textbf{and} by \proglang{R}:

<<>>=
l.upca <- as.list(upca)
@

This method allows to get an alternative text representation of the
\code{simObj}, that can be manipulated by code parsing programs or
dumped to the hard disk:

<<>>=
dput(l.upca, file="upca_list.R")
@

and this is completely reversible via:

<<>>=
l.upca <- dget("upca_list.R")
upca <- as.simObj(l.upca)
@

Sometimes it may be useful to store simObjects in an un-initialized
form, in particular if they are to be distributed in packages.

Let's demonstrate this again with a simple Lotka-Volterra model. In
the first step, we define a function, that returns a \code{simecol}
object:

<<lvgen,fig=FALSE>>=
genLV <- function() {
  new("odeModel",
    main = function (time, init, parms) {
      x <- init
      p <- parms
      dx1 <-   p["k1"] * x[1] - p["k2"] * x[1] * x[2]
      dx2 <- - p["k3"] * x[2] + p["k2"] * x[1] * x[2]
      list(c(dx1, dx2))
    },
    parms  = c(k1=0.2, k2=0.2, k3=0.2),
    times  = c(from=0, to=100, by=0.5),
    init   = c(prey=0.5, predator=1),
    solver = "lsoda"
  )
}
@

Now, the function contains the instruction, how \proglang{R} can
create a new instance of such a model. The \code{simecol} object is
not created yet, but a call to the creator function can bring it to
live:

<<lvgen2>>=
lv1 <- genLV()
plot(sim(lv1))
@

This style is used in package
\pkg{simecolModels}\footnote{\pkg{simecolModels} can be downloaded
  from the R-Forge server,
  \url{http://simecol.r-forge.r-project.org/}.}, a collection of
(mostly) published ecological models.


%\section{The initfunc}
% basics already explained in the manual
% avoiding re-initialization

%\section{Using alternative solver packages}

%\pkg{PBSddeSolve}-example  \dots
% use a time delayed differential model as example

%user-defined solvers and assignment of functions to the solver-slot \dots

%\section{Using vectorized equations}

\section{Methods to work with S4 objects}

The \proglang{S4} scheme includes several utility functions which can
be used to inspect objects and their methods. As an example,
\code{showMethods} can be used to list all different functions, that
are available for one method (here \code{sim}), depending on the
object types involved:

<<showMethods,fig=FALSE>>=
showMethods("sim")
@

Based on this information, it is now possible to inspect the source
code of the particular method, e.g. the \code{sim}-function for
differential equation models (class \code{odeModel}):

<<getMethod,fig=FALSE>>=
getMethod("sim", "odeModel")
@

In addition to this, \proglang{R} has several other functions to
inspect or manipulate objects, e.g. \code{hasMethod},
\code{findMethod}, or \code{setMethod}, please see the documentation
of these functions for details.

% hasMethod("sim", "odeModel")
% findMethod("sim", "odeModel")

% setMethod

%% ======================================================================
\chapter{Fitting Parameters}

The preferred method to obtain model parameters is direct measurement
of process rates. This can be done in own controlled experiments or by
taking results from the literature. However, not all processes are
accessible by direct measurement. In such cases process parameters can
be identified indirectly by estimating parameters from observed data.

\section{Model and data}

In order to demonstrate parameter fitting we use a simple ODE model
with two coupled differential equations:

\begin{align}
\frac{dX}{dt} &= \mu  X - D X                          \\
\frac{dS}{dt} &=  D (S_0 - S) - \frac{1}{Y} \mu  X     \\
\intertext{with Monod functional response:}
\mu  &= v_m \frac{S}{k_m + S}                           \\
\intertext{and:}
X &= \text{abundance or biomass concentration} \nonumber\\
S &= \text{substrate concentration} \nonumber\\
D &= \text{dilution rate} \nonumber\\
Y &= \text{yield constant (i.e. conversion fator between S and X)} \nonumber\\
D &= \text{dilution rate} \nonumber\\
mu  &= \text{growth rate} \nonumber\\
v_m &= \text{maximum growth rate} \nonumber\\
k_m  &= \text{half saturation constant} \nonumber
\end{align}

The chemostat model is one of the standard examples in package
\pkg{simecol}. It can be loaded like a data set and we make to working
copies, \code{cs1} and \code{cs2}:

<<fig=FALSE>>=
data(chemostat)
cs1 <- cs2 <- chemostat
@

Let's also assume we have the following test data:

<<fig=FALSE>>=
obstime <- seq(0, 20, 2)
yobs <- data.frame(
  X    = c(10, 26, 120, 197, 354, 577, 628, 661, 654, 608, 642),
  S    = c(9.6, 10.2, 9.5, 8.2, 6.4, 4.9, 4.2, 3.8, 2.5, 3.8, 3.9)
)
@

Note that in this example, \code{yobs} contains two columns (and only
two) with exactly the same column names as the state variables.

\section{Parameter estimation in simecol}

Package \pkg{simecol} has a built-in function for fitting parameters
of ODE models. In order to save computation time it is suggested to
use an efficient variable time step algorithm (e.g. \code{lsoda} and
to set external time steps of the model to the time steps contained in
the observational data:

<<fig=FALSE>>=
times(cs1)  <- obstime
solver(cs1) <- "lsoda"
@

For the most basic call to the parameter fitting function we need only
the model object, the time steps and the observational data:

<<fig=FALSE,eval=FALSE>>=
res <- fitOdeModel(cs1, obstime = obstime, yobs=yobs)
@

In this case, \textbf{all} parameters are fitted by least squares
between \textbf{all} state variables and their corresponding
observations. The start values for parameter estimation are taken from
the \code{simObj}ect. Sum of squares of the individual state variables
is weighted by the inverse standard deviation of the observations and
the Nelder-Mead algorithm is used by default.

Many options are available to control the parameter fitting, e.g. to
fit only a subset of parameters (\code{whichpar}), to control the
amount of information displayed (\code{debuglevel}, \code{trace}),
weighting of state variables (\code{sd.yobs}) or individual data
points (\code{weights}), or the algorithm used (\code{method}).

In the following, we fit only $v_m$, $k_m$ and $Y$ with the PORT
algorithm, that is in many cases faster than the other methods,
especially if the range of parameters is known (constrained
optimization, e.g. to avoid negative values for $k_m$). It as also a
good idea to assign reasonable start values to the
\code{simObj}ect. For interactive use it is recommended to set
\code{trace=TRUE}.

<<fig=FALSE>>=
whichpar <- c("vm", "km", "Y")
lower    <- c(vm=0, km=0, Y=0)
upper    <- c(vm=100, km=500, Y=200)
parms(cs1)[whichpar] <- c(vm=5, km=10, Y=100)

res <- fitOdeModel(cs1, whichpar = whichpar,
  lower = lower, upper=upper,
  obstime = obstime, yobs = yobs, method = "PORT",
  control=list(trace = FALSE))
@

The results are now stored in a list structure \code(res), from which
parameters, objective (sum of squares) or information about
convergence can be extracted:

<<fig=FALSE>>=
res
@

Future versions of \pkg{simecol} will probably contain specific
functions to extract this information in a more user-friendly style.

The success of parameter estimation can now be controlled numerically
and graphically. First we assign the new parameters to a copy of the
model object:

<<fig=FALSE>>=
parms(cs2)[whichpar] <- res$par
@

We get $r^2$ for both state variables with:

<<fig=FALSE>>=
times(cs2) <- obstime
ysim <- out(sim(cs2))
1 - var(ysim$X - yobs$X) / var(yobs$X)
1 - var(ysim$S - yobs$S) / var(yobs$S)
@

Note that time steps in data and model must be the same. However, for
producing a smooth figure it is recommended to use a smaller time
step:

<<fit1,fig=TRUE>>=
par(mfrow=c(1,2))
solver(cs2) <- "lsoda"
times(cs2) <- c(from=0, to=20, by=.1)
ysim <- out(sim(cs2))

par(mfrow=c(1,2))
plot(obstime, yobs$X, ylim = range(yobs$X, ysim$X))
lines(ysim$time, ysim$X, col="red")
plot(obstime, yobs$S, ylim= range(yobs$S, ysim$S))
lines(ysim$time, ysim$S, col="red")
@

\begin{figure}
\centering
\includegraphics[width=\textwidth]{howto-fit1}
\caption{\label{howto-fit1} Observed data and fitted model.}
\end{figure}



\section{Identification of intitial values}


\section{Parameter estimation with FME}




%% ======================================================================
\chapter{Implementing Models in Compiled Languages}

Compilation of model code can speed up simulations considerably and
there are several ways to call compiled code from \proglang{R}; so it
is possible to use functions written in \proglang{C/C++} or
\proglang{Fortran} in the ordinary way described in the ``Writing R
Extensions'' manual \citep{Rexts2006}. This can speed up computations,
but still a certain amout of communication overhead is needed because
the control is given back to \proglang{R} in every simulation step.

In addition to this basic method, it is also possible to enable direct
communication between integration routines and the model code if both
are available in compiled languages and if the direct call of a
compiled model is supported by the integrator. All integrators of the
\code{lsoda}-family of solvers support this and additional solvers may
support this in the future, see the \pkg{deSolve} documentation for
details.

\section{An Example in C}

Now, let's inspect an example. We firstly provide our model as
described in the \pkg{deSolve} vignette ``Writing Code in Compiled
Language'', here again the Lotka-Volterra-model:

\begin{verbatim}
/* file: clotka.c */
#include <R.h>

static double parms[3];

#define k1 parms[0]
#define k2 parms[1]
#define k3 parms[2]

/* It is possible to define global variables here */
static double aGlobalVar = 99.99;   // for testing only

/* initializer: same name as the dll (without extension) */
void clotka(void (* odeparms)(int *, double *)) {
  int N = 3;
  odeparms(&N, parms);
  Rprintf("model parameters succesfully initialized\n");
}

/* Derivatives */
void dlotka(int *neq, double *t, double *y,
  double *ydot, double *yout, int *ip) {

  // sanity check for the 2 'additional outputs'
  if (ip[0] < 2) error("nout should be at least 2");

  // derivatives
  ydot[0] = k1 * y[0]        - k2 * y[0] * y[1];
  ydot[1] = k2 * y[0] * y[1] - k3 * y[1];

  // the 2 additional outputs, here for demo purposes only
  yout[0] = aGlobalVar;
  yout[1] = ydot[0];
}
\end{verbatim}


Using \verb!#define! macros are a typical \proglang{C}-trick to get
readable names for the parameters. This method is simple and efficient
and of course, there are more elaborate possibilities. One alternative
is using dynamic variables, another is doing call-backs to
proglang{R}.

The \proglang{C} code can now be compiled into a so-called shared
library (on Linux) or a DLL on Windows, that can be linked to
\proglang{R}.

Compilation requires an installed \proglang{C} compiler (\pkg{gcc})
and some other tools that are quite standard on Linux, and which are
also available for the Macintosh or, form of the \pkg{R-Tools}
collection\footnote{\url{http://www.murdoch-sutherland.com/Rtools/}}
provided by Duncan Murdoch for Windows.

If the tools are installed, compilation can be done directly from
\proglang{R} with:

<<compile.clotka,fig=FALSE,eval=FALSE>>=
system("R CMD SHLIB clotka.c")
@

The result, a shared library or DLL, can now be linked to the current
\proglang{R} session with \code{dyn.load}, that we show here for
Windows, and which is quite similar for Linux \cite[see][, Writing R
Extensions for details]{Rexts2006}.  Note that you set the working
directory of \proglang{R} to the path where the DLL resides or use the
full path in the call to \code{dyn.load}.


<<clotka_R,eval=FALSE>>=
modeldll <- dyn.load("clotka.dll")
@

You can now call the derivatives \code{dlotka} of the model in the
\code{main} function of a \pkg{simecol}-object.


\section{Enabling Direct Communication Between Model and Solver}

Another, more efficient way, is to tell the solver (e.g. \code{lsoda})
directly where to find the model in the DLL. This method circumvents
the communication overhead that occurs normally for every call from
the solver to the model DLL and is especially effective if small
models are called many times, e.g. in case of small time steps or if a
model is embedder in an optimization routine.

The trick consists of two parts:

\begin{enumerate}
\item We write an almost empty \code{main} function that returns all
  the information that the ODE solver needs in form of a list,
\item Instead of putting a character reference to an existing solver
  function into the \code{solver} slot (e.g. \code{"lsoda"}) we write
  a user-defined interface to the solver and assign it to the
  solver-slot as shown in the example.
\end{enumerate}

Now, we can simulate our model as usual, but avoid interpretation and
communication overhead of \proglang{R} during the integration.

\begin{Schunk}
\begin{Sinput}
clotka <- new("odeModel",
  ## note that 'main' does not contain any equations directly
  ## but returns information where these can be found
  ## 'nout' is the number of 'additional outputs'
  main = function(time, init, parms) {
     # a list with: dllname, func, [jacfunc], nout
     list(lib     = "clotka",
          func    = "dlotka",
          jacfunc = NULL,
          nout    = 2)
  },
  ## parms, times, init are provided as usual, enabling
  ## scenario control like for 'ordinary' simecol models
  parms  = c(k1=0.2, k2=0.2, k3=0.2),
  times  = c(from=0, to=100, by=0.5),
  init   = c(prey=0.5, predator=1),
  ## special solver function that evaluates funclist
  ## and passes its contents directly to the lsoda
  ## in the 'compiled function' mode
  solver = function(init, times, funclist, parms, ...) {
    f <- funclist()
    as.data.frame(lsoda(init, times, func=f$func,
      parms = parms, dllname = f$lib, jacfunc=f$jacfunc, nout = f$nout, ...)
    )
  }
)

clotka <- sim(clotka)

## the two graphics on top are the states
## the other are additional variables returned by the C code
## (for demonstration purposes here)
plot(clotka)

## Another simulation with more time steps
times(clotka)["to"] <- 1000
plot(sim(clotka))

## another simulation with intentionally reduced accuracy
## for testing
plot(sim(clotka, atol=1))

dyn.unload(as.character(modeldll[2]))
\end{Sinput}
\end{Schunk}


You should note a considerable speed-up and you may ask if this is
still a \pkg{simecol} object, because the main parts are now in
\proglang{C} and you may also ask, why one should still write models
in \proglang{R} if \proglang{C} or \proglang{FORTRAN} are so much
faster.

The answer is that speed of computation is not the only factor.  What
counts is a good compromise between execution speed and programming
effort. Programming in scripting languages like \proglang{R} is much
more convenient than programming in compiled languages like
\proglang{C} or \proglang{FORTRAN}. Also, programming in compiled
languages does only pay its effort required if models are quite large
or if a large number of model runs is performed. Even in such cases, a
mixed \proglang{R} \textbf{and} \proglang{C} approach can be
efficient, because it is only necessary to implement the core
functionality of the model in \proglang{C} and most of data
manipulation and scenario control can be done in \proglang{R}.

\pkg{simecol} follows exactly this philosophy. Implementing everything
in \proglang{R} is highly productive if speed is of minor importance,
but you \textbf{may} use \proglang{C} etc. whenever necessary, and
even in that case you still have the scenario management and data
manipulation features of \pkg{simecol}.

%%=======================================================================
\chapter{Examples and Case Studies}




%%=======================================================================
%\bibliographystyle{jss}
\phantomsection
\addcontentsline{toc}{chapter}{References}
\bibliography{petzoldt_jss}


% clean up
<<cleanup,echo=FALSE,include=FALSE>>=
options("prompt" = "> ", "continue" = "+ ")
@
\end{document}

